{"novelty_based_exploration_efficiency": Infinity, "entropy_based_exploration_efficiency": 0.00016626357682980597, "coverage_based_exploration_efficiency": 1.0, "episode_reward": 10.0, "moving_average": 10.0, "_timestamp": 1681322021.7330806, "_runtime": 231.88833165168762, "_step": 3599}